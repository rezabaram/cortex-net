# cortex-net

## Trainable Meta-Architecture for Intelligent Agents

**cortex-net** is a research project exploring a simple but underexplored idea: what if the layer around the LLM could *learn*?

Current AI agents treat the LLM as a black box inside a hand-coded pipeline. The pipeline decides what context to include, which tools to offer, how to frame the task. When it works, it works. When it doesn't, you add more if/else branches and hope for the best.

cortex-net takes a different approach. The LLM stays frozen â€” it's already good at reasoning. But the **context assembly layer** around it becomes a set of small, trainable neural networks that learn from every interaction:

- What memories actually matter for this situation
- Which strategy will work best right now
- How confident the system should be in its answer
- How to represent the current situation for all of the above

The result: an agent that gets meaningfully better at its job over time, without fine-tuning the underlying model.

## Quick Links

- [Vision](vision.md) â€” The problem we're solving and why it matters
- [Architecture](architecture.md) â€” The Context Assembly Network in detail
- [Why This Matters](why.md) â€” What's broken in today's agents
- [Implementation Plan](implementation.md) â€” Phased roadmap from prototype to integration

## Status

âœ… **Phase 1** â€” Memory Gate (+67% vs cosine)
âœ… **Phase 2** â€” Situation Encoder (+50% on contextual retrieval)
âœ… **Phase 3** â€” Strategy Selector (10 profiles, learned selection)
âœ… **Phase 4** â€” Confidence Estimator (ECE = 0.01)
âœ… **Phase 5** â€” Context Assembler (full pipeline, 811K params)
ðŸ“Š **94 tests passing** â€” See [Implementation Plan](implementation.md).
